{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from weighted_voronoi import weighted_voronoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "\n",
    "#from weighted_voronoi_main.weighted_voronoi_main import weightedVoronoi\n",
    "from time import time\n",
    "\n",
    "startTime = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pointSource =r'../test_data/Madagascar_Fake_Capital.shp'# arcpy.GetParameterAsText(0)\n",
    "weightField = \"POP\"\n",
    "vectorOutput = r'../test_data/Madagascar_Fake_Output.shp'\n",
    "bufferDegrees = 5.0\n",
    "cellSize = 0.008333333333333\n",
    "distMethod = \"vincenty\"\n",
    "smoothPolys = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split out the destination file into path and name\n",
    "vectorOutput = vectorOutput.replace(\"\\\\\", \"/\")\n",
    "vectorOutputPath = vectorOutput[:vectorOutput.rindex(\"/\")]\n",
    "vectorOutputName = vectorOutput[vectorOutput.rindex(\"/\")+1:]\n",
    "\n",
    "# Get the OID field name\n",
    "oidField = arcpy.Describe(pointSource).OIDFieldName\n",
    "\n",
    "\n",
    "def cleanup_scratch(refs):\n",
    "    \"\"\"\n",
    "    Cleanup intermediate files that may be in scratch\n",
    "    \"\"\"\n",
    "    # Cleanup intermediate files that may be around\n",
    "    for r in refs:\n",
    "        arcpy.Delete_management(r)\n",
    "\n",
    "\n",
    "def cell_center_lat(row, initlat, ysize, numrows):\n",
    "    \"\"\"\n",
    "    The latitude for the cell centers in a row\n",
    "    \"\"\"\n",
    "    return initlat + (numrows - row - 1) * ysize\n",
    "\n",
    "\n",
    "def cell_center_lng(col, initlng, xsize, numcols):\n",
    "    \"\"\"\n",
    "    The longitude for the cell centers in a column\n",
    "    \"\"\"\n",
    "    return initlng + (col) * xsize\n",
    "\n",
    "\n",
    "# Get the spatial reference of the source (and dest)\n",
    "spatialRef = arcpy.Describe(pointSource).spatialReference\n",
    "\n",
    "# Split out the destination file into path and name\n",
    "vectorOutputPath = vectorOutput[:vectorOutput.rindex(\"/\")]\n",
    "vectorOutputName = vectorOutput[vectorOutput.rindex(\"/\")+1:]\n",
    "\n",
    "# Intermediate features/rasters\n",
    "vectorIntermediate = arcpy.env.scratchGDB + \"/DVWPoly_vect_int\"\n",
    "rasterIntermediate = arcpy.env.scratchGDB + \"/DVWPoly_rast_int\"\n",
    "rasterVals = arcpy.env.scratchGDB + \"/DVWPoly_rast_vals\"\n",
    "rasterIds = arcpy.env.scratchGDB + \"/DVWPoly_rast_ids\"\n",
    "extentBuffered = arcpy.env.scratchGDB + \"/DVWPoly_extent_buffered\"\n",
    "\n",
    "# References to anything that might be in scratch\n",
    "scratchRefs = [vectorIntermediate, rasterIntermediate, rasterVals,\n",
    "               rasterIds, extentBuffered]\n",
    "\n",
    "# Cleanup anything that may be leftover in scratch\n",
    "cleanup_scratch(scratchRefs)\n",
    "\n",
    "# Ensure that a scratch GDB is set\n",
    "if arcpy.env.scratchGDB is None:\n",
    "    arcpy.AddError(\"No scratch geodatabase is set\")\n",
    "    cleanup_scratch(scratchRefs)\n",
    "    raise arcpy.ExecuteError\n",
    "\n",
    "# Ensure that the point source is in a GCS\n",
    "if spatialRef.type != \"Geographic\":\n",
    "    arcpy.AddError(\"Must use a geographic coordinate system\")\n",
    "    cleanup_scratch(scratchRefs)\n",
    "    raise arcpy.ExecuteError\n",
    "\n",
    "# Get the extent of the point source and create as a polygon\n",
    "sourceExtent = arcpy.Describe(pointSource).extent\n",
    "extentPoints = arcpy.Array()\n",
    "extentPoints.add(sourceExtent.lowerLeft)\n",
    "extentPoints.add(sourceExtent.upperLeft)\n",
    "extentPoints.add(sourceExtent.upperRight)\n",
    "extentPoints.add(sourceExtent.lowerRight)\n",
    "extentPoints.add(sourceExtent.lowerLeft)\n",
    "sourceExtentPoly = arcpy.Polygon(extentPoints)\n",
    "\n",
    "# Buffer the point source extent by bufferDegrees and update\n",
    "# processing extent environment variable\n",
    "arcpy.Buffer_analysis(sourceExtentPoly, extentBuffered,\n",
    "                      bufferDegrees, \"OUTSIDE_ONLY\")\n",
    "initExtent = arcpy.env.extent\n",
    "arcpy.env.extent = arcpy.Describe(extentBuffered).extent\n",
    "\n",
    "# Create a raster of weight values from weightField\n",
    "arcpy.FeatureToRaster_conversion(\n",
    "    in_features=pointSource,\n",
    "    field=weightField,\n",
    "    out_raster=rasterVals,\n",
    "    cell_size=cellSize)\n",
    "valRaster = arcpy.Raster(rasterVals)\n",
    "\n",
    "# Create a raster of OIDs\n",
    "arcpy.FeatureToRaster_conversion(\n",
    "    in_features=pointSource,\n",
    "    field=oidField,\n",
    "    out_raster=rasterIds,\n",
    "    cell_size=cellSize)\n",
    "oidRaster = arcpy.Raster(rasterIds)\n",
    "\n",
    "# Return to the initial processing extent\n",
    "arcpy.env.extent = initExtent\n",
    "\n",
    "# Create value and OID numpy arrays from rasters\n",
    "arcpy.AddMessage(\"Creating value and OID numpy arrays\")\n",
    "valArray = arcpy.RasterToNumPyArray(valRaster, nodata_to_value=0)\n",
    "oidArray = arcpy.RasterToNumPyArray(oidRaster, nodata_to_value=-1)\n",
    "\n",
    "\n",
    "lowerLeft = arcpy.Point(oidRaster.extent.XMin, oidRaster.extent.YMin)\n",
    "llCellX = oidRaster.extent.XMin + 0.5 * oidRaster.meanCellWidth\n",
    "llCellY = oidRaster.extent.YMin + 0.5 * oidRaster.meanCellHeight\n",
    "cellSizeY = oidRaster.meanCellHeight\n",
    "cellSizeX = oidRaster.meanCellWidth\n",
    "rasterHeight = int(oidRaster.height)\n",
    "rasterWidth = int(oidRaster.width)\n",
    "\n",
    "arcpy.AddMessage(\"Rasters height: %d\" % rasterHeight)\n",
    "arcpy.AddMessage(\"Rasters width: %d\" % rasterWidth)\n",
    "\n",
    "del valRaster\n",
    "del oidRaster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arrays of the cell center latitudes for each row and longitudes for\n",
    "# each column\n",
    "arcpy.AddMessage(\"Determine lat for each row, lng for each column\")\n",
    "rowLats = np.array(\n",
    "                    [cell_center_lat(x, llCellY, cellSizeY, rasterHeight)\n",
    "                     for x\n",
    "                     in range(rasterHeight)])\n",
    "\n",
    "colLngs = np.array(\n",
    "                    [cell_center_lng(y, llCellX, cellSizeX, rasterWidth)\n",
    "                     for y\n",
    "                     in range(rasterWidth)])\n",
    "\n",
    "# Get the row/col refs for point locations in the raster and build a\n",
    "# list of points including OID and coordinates\n",
    "arcpy.AddMessage(\"Building up points to check\")\n",
    "pointLocations = zip(*map(list, np.where(oidArray != -1)))\n",
    "#checkPoints = [\n",
    "#    {\n",
    "#        \"cell\": l,\n",
    "#        \"coords\": (rowLats[l[0]], colLngs[l[1]]),\n",
    "#        \"oid\": oidArray[l],\n",
    "#        \"val\": valArray[l]\n",
    "#    }\n",
    "#    for l in pointLocations\n",
    "#]\n",
    "\n",
    "oidUse = oidArray[oidArray!=-1]\n",
    "valUse = valArray[oidArray!=-1]\n",
    "latsUse = np.asarray([rowLats[l[0]] for l in pointLocations])\n",
    "lonsUse = np.asarray([colLngs[l[1]] for l in pointLocations])\n",
    "del oidArray\n",
    "del valArray\n",
    "# the cython has been compiled for int32 specifically\n",
    "assignmentsDType = np.int32\n",
    "vCalc = weighted_voronoi(rowLats, colLngs, oidUse, valUse, latsUse, lonsUse)\n",
    "assignments = np.asarray(vCalc.calculate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the array back to a raster\n",
    "arcpy.AddMessage(\"Assignments completed, saving to raster\")\n",
    "tempRast = arcpy.NumPyArrayToRaster(assignments, lowerLeft,\n",
    "                                   cellSizeX, cellSizeY)\n",
    "tempRast.save(rasterIntermediate)\n",
    "del tempRast\n",
    "\n",
    "# Define the raster projection\n",
    "arcpy.DefineProjection_management(rasterIntermediate, spatialRef)\n",
    "\n",
    "# Create an intermediate polygon feature class in scratch because\n",
    "# AlterField_management doesn't appear to work with the output shapefile.\n",
    "arcpy.AddMessage(\"Polygonizing raster\")\n",
    "arcpy.RasterToPolygon_conversion(\n",
    "    in_raster=rasterIntermediate,\n",
    "    out_polygon_features=vectorIntermediate,\n",
    "    simplify=(\"SIMPLIFY\" if smoothPolys else \"NO_SIMPLIFY\"),\n",
    "    raster_field=\"Value\")\n",
    "\n",
    "# Delete the kinda-duplicative Id field\n",
    "arcpy.AddMessage(\"Cleaning up polygon fields\")\n",
    "arcpy.DeleteField_management(vectorIntermediate, \"Id\")\n",
    "\n",
    "# Rename GRIDCODE field to align with the original OID fieldname, e.g. ORIG_FID\n",
    "arcpy.AlterField_management(vectorIntermediate,\n",
    "                            \"GRIDCODE\",\n",
    "                            str(\"ORIG_\" + oidField))\n",
    "\n",
    "# Copy the intermediate vector output to its final destination\n",
    "arcpy.AddMessage(\"Saving final polygon output to {}\".format(vectorOutput))\n",
    "arcpy.FeatureClassToFeatureClass_conversion(\n",
    "    in_features=vectorIntermediate,\n",
    "    out_path=vectorOutputPath,\n",
    "    out_name=vectorOutputName\n",
    "  )\n",
    "\n",
    "# Cleanup intermediate files\n",
    "cleanup_scratch(scratchRefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#oidUse\n",
    "oidUse = np.array([1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valUse\n",
    "valUse = np.array([  68973.,  124745.,  160963.,  128893.,   54578.,  127628.,\n",
    "         94394.,   53067.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#latsUse\n",
    "latsUse = np.array([-12.31252035, -15.71252035, -18.16252035, -18.91252035,\n",
    "       -19.67085368, -21.44585368, -23.34585368, -25.16252035])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lonsUse\n",
    "lonsUse=np.array([ 49.28752035,  46.31252035,  49.37918701,  47.51252035,\n",
    "        47.31252035,  47.06252035,  43.66252035,  46.07918701])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colLngs = np.arange(46,49,0.008333333333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowLats = np.arange(-12,-26,-0.008333333333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.        , -12.00833333, -12.01666667, ..., -25.98333333,\n",
       "       -25.99166667, -26.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowLats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignments = weighted_voronoi(rowLats, colLngs, oidUse, valUse, latsUse, lonsUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = assignments.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 1, 1, 1],\n",
       "       [2, 2, 2, ..., 1, 1, 1],\n",
       "       [2, 2, 2, ..., 1, 1, 1],\n",
       "       ..., \n",
       "       [8, 8, 8, ..., 6, 6, 6],\n",
       "       [8, 8, 8, ..., 6, 6, 6],\n",
       "       [8, 8, 8, ..., 6, 6, 6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
